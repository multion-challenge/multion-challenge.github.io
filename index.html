<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Project page for MultiON EAI Challenge CVPR 2023.">
    <meta name="author" content="SFU">
    <meta name="keywords" content="embodied ai workshop, vision navigation, multion, multion challenge, cvpr 2023 ">

    <title>MultiON EAI Challenge CVPR 2023</title>

    <!--FACEBOOK-->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="http://multion-challenge.cs.sfu.ca" />
    <meta property="og:title" content="MultiON EAI Challenge CVPR 2023" />
    <meta property="og:description" content="Project page for MultiON EAI Challenge CVPR 2023." />

    <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="MultiON EAI Challenge CVPR 2023" />
    <meta name="twitter:description" content="Project page for MultiON EAI Challenge CVPR 2023." />

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">

    <link href="https://fonts.googleapis.com/css?family=Lato:400,400i|PT+Serif:700" rel="stylesheet">
    <link rel="stylesheet" href="dist/css/style.css">
    <link rel="stylesheet" href="dist/css/new_style.css">
    
</head>

<body class="is-boxed has-animations">
    <div class="body-wrap boxed-container">
        <header class="site-header">
            <div class="btn-group" style="float:right;">
                <button class="btn btn-danger dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    Challenges
                </button>
                <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                    <a class="dropdown-item" href="./index.html">2023</a><br>
                    <a class="dropdown-item" href="./2022.html">2022</a><br>
                    <a class="dropdown-item" href="./2021.html">2021</a>
                </div>
              </div>
        </header>

        <main>
            <section class="hero text-light text-center">
                <div class="container-sm">
                    <div class="hero-inner">
                        <h1 class="hero-title h2-mobile mt-0 is-revealing">
                            Multi-Object Navigation (MultiON) Challenge
                        </h1>
                        <div>
                            Held in conjunction with the <a href="https://embodied-ai.org/" target="_blank">Embodied AI
                                Workshop</a> at CVPR 2023
                        </div>
                        <br>
                    </div>
                </div>
            </section>

            <div class="container">
                <div class="row">
                    <div class="has-top-divider">&nbsp;</div>
                    <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12">
                        <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 text-center">
                            <image src="videos/2023/rgb.gif" class="img-fluid img-thumbnail rounded"
                                alt="cylinder-track"></image>
                                <figcaption class="text-center gif-img-caption">
                                    An example episode from the MultiON challenge 2023.
                                </figcaption>
                        </div>
                        <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 text-center">
                            <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 text-center goal-img">
                                Goals:&nbsp;
                                <image src="videos/2023/highlighter.jpg" class="img-fluid img-thumbnail" style="width:40px;height:50px;"
                                alt="real-goal-1"></image> ⟶
                                <image src="videos/2023/pedestal_fan.jpg" class="img-fluid img-thumbnail" style="width:50px;height:50px;"
                                alt="real-goal-2"></image> ⟶
                                <image src="videos/2023/vacuum_cleaner.jpg" class="img-fluid img-thumbnail" style="width:50px;height:50px;"
                                alt="real-goal-3"></image>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <section class="overview section text-center">
                <div class="has-top-divider">&nbsp;</div>
                <div class="container">
                    <div class="overview-inner section-inner">
                        <h2 class="section-title mt-0">Overview</h2>
                        Multi-Object Navigation (MultiON) challenge is hosted at Embodied AI workshop, CVPR 2023. This
                        challenge is built upon the task introduced in <a
                            href="https://shivanshpatel35.github.io/multi-ON/">MultiON: Benchmarking Semantic Map Memory
                            using Multi-Object Navigation</a> (NeurIPS 2020). MultiON is a long-horizon generalization
                        of the object-navigation task, i.e., where the agent has to navigate to multiple goals.
                    </div>
                </div>
    
            </section>

    <section class="citation section text-left">
        <div class="container">
            <div class="participation-inner section-inner">

                <h2 class="section-title mt-0">Dates</h2>
                <div>
                    <table class="dates-table">
                        <tr>
                            <td>Challenge starts <br>(Dataset and starter code <a href="https://github.com/3dlg-hcvc/multion-challenge" target="_blank"> available </a> and <br>EvalAI opens up for
                                Minival Phase submissions)</td>
                            <td>March 20, 2023</td>
                        </tr>
                        <tr>
                            <td><a href="https://eval.ai/web/challenges/challenge-page/2002/leaderboard">Leaderboard</a> opens <br>(Test Standard Phase and <br>Test Challenge Phase submissions)
                            </td>
                            <td>March 20, 2023</td>
                        </tr>
                        <tr>
                            <td>Challenge submission deadline</td>
                            <td>June 3, 2023 (AoE)</td>
                        </tr>
                        <tr>
                            <td>Winner announcement at <a href="https://embodied-ai.org/">Embodied AI Workshop, CVPR
                                    2023</a></td>
                            <td>June, 2023</td>
                        </tr>
                    </table>
                </div>

            </div>

        </div>
    </section>

    <section class="task section text-left">
        <div class="container">
            <div class="section-inner">
                <h2 class="section-title mt-0">Task</h2>
                In MultiON, an agent is tasked with navigating to a sequence of objects. These objects are flexibly
                inserted on surfaces into a realistic 3D environment. The task is based on the <a
                    href="http://aihabitat.org/">Habitat platform</a> and <a
                    href="https://aihabitat.org/datasets/hm3d-semantics/">Habitat-Matterport 3D Semantics (HM3D-Semantics)</a> scenes.
                <br><br>
                Each episode contains 3 target objects randomly sampled from a set of 50 classes. For every class
                there are multiple objects available (e.g., for the "notebook" class there are 9 different objects). We did this to add instance-level variation within each category and test the perception capabilities of the agents. We used 3D objects from <a href="https://shapenet.org">ShapeNet</a>.
                

                Additionally:
                <ul>
                    <li>
                        The training set contains only 40 possible classes, the validation 45 (with 5 "zero-shot objects"), and the test/test
                        challenge have 45 (with 5 "zero-shot objects", different from the validation ones).
                    </li>
                    <li>
                        Each episode contains 5 distractor (non-target) objects randomly scattered on surfaces around the
                        environment, to increase the difficulty of the task.
                    </li>
                </ul>

                In summary, in each episode, the agent is initialized at a random starting position and orientation in
                an unseen environment and provided a sequence of 3 target objects randomly sampled (without replacement)
                from the set of 50 objects. The agent must navigate to each target object in the sequence (in the given
                order), avoiding distractor objects and and call the FOUND action to indicate discovery.
                The agent has access to an RGB-D camera and a noiseless GPS+Compass sensor. GPS+Compass sensor provides
                the agent's current location and orientation information relative to the start of the episode.
            </div>
        </div>
    </section>

    <section class="evaluation section text-left has-top-divider">
        <div class="container">
            <div class="evaluation-inner section-inner">
                <h2 class="section-title mt-0">Evaluation Details</h2>
                The episode terminates when an agent discovers all objects in the sequence of the current episode or
                when it calls an incorrect FOUND action. A FOUND action is incorrect if it is called when the agent is
                not within a 1.5m from its current target object. Note that this does not require the
                agent to be viewing the object at the time of calling FOUND. After the episode terminates, the agent is
                evaluated using the Progress and PPL metrics that are defined below.<br>
                <strong>Progress</strong>: The proportion of objects correctly found in the episode.<br>
                <strong>PPL</strong>: Progress weighted by path length. PPL quantifies the efficiency of agent's
                trajectory with respect to the optimal trajectory.<br>
            </div>
        </div>
    </section>

    <section class="citation section text-left has-top-divider">
        <div class="container">
            <div class="participation-inner section-inner">
                <h2 class="section-title mt-0">Submission Guidelines</h2>
                Participants must make submission through our <a
                    href="https://eval.ai/web/challenges/challenge-page/2002/overview">EvalAI</a> page. There are three
                phases in the challenge.
                <h4 class="section-title mt-8">Phase 1: Minival Phase</h4>
                    This phase evaluates MultiON agents on the minival set of the MultiON dataset. This phase is meant to be used for sanity checking the
                    results of remote evaluation against your local evaluations.
                <h4 class="section-title mt-8">Phase 2: Test Standard Phase</h4>
                    This results of this phase will be used to prepare the public leaderboard for the challenge. We suggest using this
                    phase for reporting results in papers and for comparing with other methods. Each team is allowed
                    a maximum of 3 submissions per day for this phase.
                <h4 class="section-title mt-8">Phase 3: Test Challenge Phase</h4>
                    Only submissions made in this phase are considered as entries to the MultiON
                        Challenge since this will be used to decide the winners. Each team is allowed a
                    total of 3 submissions to this phase until the end of this phase.  
                For detailed submission instruction, please refer <a
                        href="https://github.com/3dlg-hcvc/multion-challenge">this</a>.
            </div>
        </div>
    </section>

    <section class="citation section text-left has-top-divider">
        <div class="container">
            <div class="participation-inner section-inner">
                <h2 class="section-title mt-0">Challenge Updates</h2>
                Any updates related to the challenge will be posted here. Please join the Google Group email list to receive updates about the challenge: <a href="https://groups.google.com/g/multion-challenge-2023/">click here</a> to join or send an
                email to
                <a
                    href="mailto:multion-challenge-2023+subscribe@googlegroups.com?&subject=Subscribe to email list&body=Subscribe">multion-challenge-2023+subscribe@googlegroups.com</a>.
            </div>
        </div>
    </section>


    <section class="citation section text-left">
        <div class="container">
            <div class="participation-inner section-inner">
                <h2 class="section-title mt-0">Terms and Conditions</h2>
                The Habitat-Sim is released under <a
                    href="https://github.com/facebookresearch/habitat-sim/blob/master/LICENSE" target="_blank">MIT
                    license</a>.
                To use HM3D-Semantics dataset, please refer <a href="https://aihabitat.org/datasets/hm3d-semantics/"
                    target="_blank">here</a>.
                If you use Habitat-Sim or the MultiON dataset in a paper, please consider citing the following
                publications:
                <div>
                    <pre style="background-color: rgb(189, 211, 207);">
<code style="background-color: rgb(189, 211, 207); color: black">@inproceedings{habitat19iccv,
    title     =     {Habitat: {A} {P}latform for {E}mbodied {AI} {R}esearch},
    author    =     {Manolis Savva and Abhishek Kadian and Oleksandr Maksymets and Yili Zhao and Erik Wijmans and Bhavana Jain and Julian Straub and Jia Liu and Vladlen Koltun and Jitendra Malik and Devi Parikh and Dhruv Batra},
    booktitle =     {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      =     {2019}
    }</code></pre>
                    <pre style="background-color: rgb(189, 211, 207);"><code style="background-color: rgb(189, 211, 207); color: black">@inproceedings{wani2020multion,
    title       =   {Multi-ON: Benchmarking Semantic Map Memory using Multi-Object Navigation},
    author      =   {Saim Wani and Shivansh Patel and Unnat Jain and Angel X. Chang and Manolis Savva},
    booktitle   =   {Neural Information Processing Systems (NeurIPS)},
    year        =   {2020},
    }</code></pre>
                </div>

            </div>
        </div>
    </section>

    <section class="organizers section text-left">
        <div class="container">
            <div class="organizers-inner section-inner">

                <h2 class="section-title mt-0">Organizers</h2>
                <div class="row" id="organizers-container">
                    <div class="organizers-column">
                        <a href="https://sonia-raychaudhuri.github.io/">
                            <img src="images/sonia.jpg" alt="Sonia Raychaudhuri" style="width:200px">
                        </a>
                        <div class="text-center">
                            <a href="https://sonia-raychaudhuri.github.io/">Sonia Raychaudhuri</a><br>
                            SFU
                        </div>
                    </div>
                    <div class="organizers-column">
                        <a href="https://www.tommasocampari.com/">
                            <img src="images/campari.jpg" alt="Tommaso Campari" style="width:200px">
                        </a>
                        <div class="text-center">
                            <a href="https://www.tommasocampari.com/">Tommaso Campari</a><br>
                            SFU, U of Padova, FBK
                        </div>
                    </div>
                    <div class="organizers-column">
                        <a href="https://unnat.github.io/">
                            <img src="images/unnat.jpeg" alt="Unnat Jain" style="width:200px">
                        </a>
                        <div class="text-center">
                            <a href="https://unnat.github.io/">Unnat Jain</a><br>
                            Facebook AI Research
                        </div>
                    </div>
                    <div class="organizers-column">
                        <a href="https://angelxuanchang.github.io/">
                            <img src="images/angel.jpg" alt="Angel X. Chang" style="width:200px">
                        </a>
                        <div class="text-center">
                            <a href="https://angelxuanchang.github.io/">Angel X. Chang</a><br>
                            SFU
                        </div>
                    </div>
                    <div class="organizers-column">
                        <a href="https://msavva.github.io/">
                            <img src="images/manolis.jpg" alt="Manolis Savva" style="width:200px">
                        </a>
                        <div class="text-center">
                            <a href="https://msavva.github.io/">Manolis Savva</a><br>
                            SFU
                        </div>
                    </div>
                </div>

            </div>

        </div>
    </section>

    </main>

    </div>
    <!-- Bootstrap core JavaScript
        ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
</body>

</html>